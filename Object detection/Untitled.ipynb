{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<class 'cv2.dnn_DetectionModel'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-68be6569669d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mweightsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'frozen_inference_graph.pb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn_DetectionModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweightsPath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfigPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInputSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInputScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;36m127.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class 'cv2.dnn_DetectionModel'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "thres = 0.5 # Threshold to detect object\n",
    "nms_threshold = 0.5\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "cap.set(10,70)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "starting_time= time.time()\n",
    "frame_id = 0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out2 = cv2.VideoWriter('output.mp4',fourcc, 15.0, (1280,360))\n",
    "#out2 = cv2.VideoWriter('output.avi', -1, 20.0, (640,480))\n",
    "classNames= []\n",
    "classFile = 'coco.names'\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    frame_id+=1\n",
    "    classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "    print(classIds,bbox)\n",
    "    \n",
    "    if len(classIds) != 0:\n",
    "        for classId, confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "            cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "            cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(img,str(round(confidence*100,2)),(box[0]+200,box[1]+30),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "\n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps=frame_id/elapsed_time\n",
    "    cv2.putText(img,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),2)\n",
    "    out2.write(img)\n",
    "    cv2.imshow(\"Output\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27: #esc key stops the process\n",
    "        break;\n",
    "    \n",
    "cap.release()\n",
    "out2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "thres = 0.45 # Threshold to detect object\n",
    "nms_threshold = 0.2\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "starting_time= time.time()\n",
    "frame_id = 0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out2 = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "# cap.set(3,1280)\n",
    "# cap.set(4,720)\n",
    "# cap.set(10,150)\n",
    " \n",
    "classNames= []\n",
    "classFile = 'coco.names'\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    " \n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    " \n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    frame_id+=1\n",
    "    classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "    bbox = list(bbox)\n",
    "    confs = list(np.array(confs).reshape(1,-1)[0])\n",
    "    confs = list(map(float,confs))\n",
    "    #print(type(confs&#91;0]))\n",
    "    #print(confs)\n",
    " \n",
    "    indices = cv2.dnn.NMSBoxes(bbox,confs,thres,nms_threshold)\n",
    "    #print(indices)\n",
    " \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        x,y,w,h = box[0],box[1],box[2],box[3]\n",
    "        cv2.rectangle(img, (x,y),(x+w,h+y), color=(0, 255, 0), thickness=2)\n",
    "        cv2.putText(img,classNames[classIds[i][0]-1].upper(),(box[0]+10,box[1]+30),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    " \n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps=frame_id/elapsed_time\n",
    "    cv2.putText(img,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),2)\n",
    "   \n",
    "    cv2.imshow('Output',img)\n",
    "    out2.write(img)\n",
    "    key = cv2.waitKey(1)\n",
    "                 \n",
    "    if key == 27: #esc key stops the process\n",
    "        break;\n",
    "    \n",
    "cap.release() \n",
    "out2.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TU DZIA≈ÅAM TERAZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "thres = 0.45 # Threshold to detect object\n",
    "nms_threshold = 0.2\n",
    "cap = cv2.VideoCapture(\"Pexels Videos 4698.mp4\")\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<class 'cv2.dnn_DetectionModel'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f9d50426bfcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mweightsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'frozen_inference_graph.pb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn_DetectionModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweightsPath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfigPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInputSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInputScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;36m127.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class 'cv2.dnn_DetectionModel'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "thres = 0.45 # Threshold to detect object\n",
    "nms_threshold = 0.2\n",
    "cap = cv2.VideoCapture(0)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "starting_time= time.time()\n",
    "frame_id = 0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out2 = cv2.VideoWriter('output.avi', fourcc, 20.0, (int(width), int(height)))\n",
    "# cap.set(3,1280)\n",
    "# cap.set(4,720)\n",
    "# cap.set(10,150)\n",
    " \n",
    "classNames= []\n",
    "classFile = 'coco.names'\n",
    "with open(classFile,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    " \n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    " \n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    frame_id+=1\n",
    "    classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "    bbox = list(bbox)\n",
    "    confs = list(np.array(confs).reshape(1,-1)[0])\n",
    "    confs = list(map(float,confs))\n",
    "    #print(type(confs&#91;0]))\n",
    "    #print(confs)\n",
    " \n",
    "    indices = cv2.dnn.NMSBoxes(bbox,confs,thres,nms_threshold)\n",
    "    #print(indices)\n",
    " \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = bbox[i]\n",
    "        x,y,w,h = box[0],box[1],box[2],box[3]\n",
    "        cv2.rectangle(img, (x,y),(x+w,h+y), color=(0, 255, 0), thickness=2)\n",
    "        cv2.putText(img,classNames[classIds[i][0]-1].upper(),(box[0]+10,box[1]+30),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    " \n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps=frame_id/elapsed_time\n",
    "    cv2.putText(img,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),2)\n",
    "   \n",
    "    cv2.imshow('Output',img)\n",
    "    out2.write(img)\n",
    "    key = cv2.waitKey(1)\n",
    "                 \n",
    "    if key == 27: #esc key stops the process\n",
    "        break;\n",
    "    \n",
    "cap.release() \n",
    "out2.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'annotation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-34c258ba996f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mobjNumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# for each object in the video.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"annotation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mobjNumber\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mlabelName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'annotation'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Find OpenCV version\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "def getFPS(video):\n",
    "    major_version = major_ver;\n",
    "    if not major_version:\n",
    "        (major_version, _, _) = (cv2.__version__).split('.')\n",
    "        \n",
    "    if int(major_version)  < 3 :\n",
    "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    else :\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return fps\n",
    "    \n",
    "\n",
    "def getFrameAtTime(video, timeInSec, fps):\n",
    "    frameNumber = int(timeInSec* fps);\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, frameNumber-1)\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        print (\"Failed to get image from frame number \" + str(frameNumber));\n",
    "    return frame;\n",
    "\n",
    "colors=[(255,0,0,120), (0,255,0,120), (0,0,255,120), (255,255,0,120), \n",
    "        (0,255,255,120), (255,0,255,120), (128,128,0,120), (155,0,155,120), (155,155,20,120)]\n",
    "videoPath = \"Pexels Videos 4698.mp4\"\n",
    "outpath = \"test\"\n",
    "dataturks_JSON_FilePath = \"Pexels Videos 4698.json\"\n",
    "lines = []\n",
    "with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "data = json.loads(lines[0]) #just showing this for one video.\n",
    "\n",
    "# read the video from local filesystem.\n",
    "vidcap = cv2.VideoCapture(videoPath)\n",
    "fps = getFPS(vidcap)\n",
    "\n",
    "columns = 3\n",
    "objNumber = 0\n",
    "# for each object in the video.\n",
    "for obj in data[\"annotation\"]:\n",
    "    objNumber +=1\n",
    "    labelName = obj[\"label\"]\n",
    "    print(\"Object #\" + str(objNumber) + \": \" + labelName)\n",
    "    boundingColor = colors[objNumber%len(colors)]\n",
    "    figure=plt.figure(figsize=(15,10))\n",
    "    # display all the positions of the object in the video.\n",
    "    positionNumber = 0;\n",
    "    for pos in obj[\"positions\"]:\n",
    "        time = pos[\"time\"] #the time of bounding box.\n",
    "        points = pos[\"points\"]\n",
    "        frame = getFrameAtTime(vidcap, time, fps); #extract the frame at the given time,\\.\n",
    "        \n",
    "        #save the frame as an image.\n",
    "        num = int(time*fps)\n",
    "        outImgPath = outpath + \"cars_image%d.jpg\" % num\n",
    "        cv2.imwrite(outImgPath, frame)\n",
    "        \n",
    "        #draw a bounding box on the frame image.\n",
    "        im = Image.open(outImgPath)\n",
    "        width, height = im.size\n",
    "        draw = ImageDraw.Draw(im, 'RGBA')\n",
    "        #draw the bounding box.\n",
    "        draw.rectangle(((points[0][0]*width,points[0][1]*height), (points[3][0]*width,points[3][1]*height)), boundingColor)\n",
    "        #display the image in columns.\n",
    "        figure.add_subplot(len(obj[\"positions\"])/columns + 1, columns, positionNumber + 1)\n",
    "        plt.imshow(np.asarray(im))\n",
    "        positionNumber+=1\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
